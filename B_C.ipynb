{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rachana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rachana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('edmunds.csv')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       braking - sorry 70 0 braking 189 reported c & ...\n",
      "1       new 2004 accord drove driveway last night . go...\n",
      "2       love numbers , compare performance price numbe...\n",
      "3       kd , people buy tl accord , reason bought 330 ...\n",
      "4       pg48477 ... prove point . luxury primary crite...\n",
      "                              ...                        \n",
      "4995    `` meaningless '' guess 's meaningless actuall...\n",
      "4996    guess everyone hung whole msrp value thing . g...\n",
      "4997    please stop yelling ! consider used camaro z28...\n",
      "4998    response exepected ... discounting areas bmw e...\n",
      "4999    `` please mountain , curvy , wavy road nonsens...\n",
      "Name: body, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "df['body']=df['body'].str.lower()\n",
    "\n",
    "df['body'] = df['body'].astype(str).apply(remove_stopwords)\n",
    "print(df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the brand names to the car names\n",
    "mapping_df = pd.read_csv('car_models_and_brands.csv')\n",
    "model_to_brand = dict(zip(mapping_df['Model'], mapping_df['Brand']))\n",
    "def replace_model_with_brand(comment):\n",
    "    for model, brand in model_to_brand.items():\n",
    "        comment = comment.replace(model, brand)\n",
    "    return comment\n",
    "\n",
    "df['body'] = df['body'].str.lower().apply(replace_model_with_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=mapping_df['Brand'].unique()\n",
    "values_to_remove = ['car', 'seat', 'problem','\"hyundai,\"','hyundai.','\"kia,\"','kia.']\n",
    "\n",
    "brands = [x for x in brands if x not in values_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bmw': 1433, 'honda': 426, 'acura': 544, 'nissan': 293, 'subaru': 217, 'infiniti': 399, 'sedan': 672, 'hyundai': 109, 'chevrolet': 106, 'toyota': 321, 'pontiac': 52, 'mercedes-benz': 205, 'audi': 413, 'ford': 128, 'mazda': 69, 'lincoln': 55, 'cadillac': 107, 'chrysler': 62, 'dodge': 55, 'volkswagen': 169, 'volvo': 122, 'mitsubishi': 22, 'saturn': 11, 'kia': 23, 'suzuki': 17, 'buick': 29, 'mercury': 5}\n"
     ]
    }
   ],
   "source": [
    "brand_freq = {}\n",
    "\n",
    "# Iterate through the \"body\" column of the target DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    body_text = row['body']\n",
    "    # Check for NaN values and skip them\n",
    "    if not isinstance(body_text, str) and np.isnan(body_text):\n",
    "        continue\n",
    "    \n",
    "    # Split the \"body\" text into words\n",
    "    words = body_text.split()\n",
    "\n",
    "    words = list(set(words))\n",
    "\n",
    "    # Count the frequency of brand names in the \"body\" text\n",
    "    for word in words:\n",
    "        if word in brands:\n",
    "            brand_freq[word] = brand_freq.get(word, 0) + 1\n",
    "\n",
    "# Now, brand_freq dictionary contains the frequency counts of brand names in the \"body\" column\n",
    "print(brand_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmw: 1433\n",
      "sedan: 672\n",
      "acura: 544\n",
      "honda: 426\n",
      "audi: 413\n",
      "infiniti: 399\n",
      "toyota: 321\n",
      "nissan: 293\n",
      "subaru: 217\n",
      "mercedes-benz: 205\n"
     ]
    }
   ],
   "source": [
    "sorted_dict = sorted(brand_freq.items(), key=lambda item: item[1],reverse=True)\n",
    "top_10_brands=sorted_dict[:10]\n",
    "for brand, frequency in top_10_brands:\n",
    "    print(f'{brand}: {frequency}')\n",
    "top_10_list = [item[0] for item in top_10_brands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift(honda, toyota) = 2.41\n",
      "Lift(nissan, toyota) = 1.97\n",
      "Lift(honda, nissan) = 1.84\n",
      "Lift(acura, infiniti) = 1.45\n",
      "Lift(audi, mercedes-benz) = 1.18\n",
      "Lift(acura, audi) = 0.85\n",
      "Lift(acura, honda) = 0.73\n",
      "Lift(audi, infiniti) = 0.73\n",
      "Lift(audi, bmw) = 0.65\n",
      "Lift(bmw, infiniti) = 0.64\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store brand mentions per post\n",
    "brand_mentions_per_post = {brand: set() for brand in top_10_list}\n",
    "\n",
    "# Initialize dictionaries to store brand co-mentions and individual brand mentions\n",
    "co_mentions = {}\n",
    "for brand1 in top_10_list:\n",
    "    co_mentions[brand1] = {}\n",
    "    for brand2 in top_10_list:\n",
    "        co_mentions[brand1][brand2] = 0\n",
    "individual_mentions = {brand: 0 for brand in top_10_list}\n",
    "\n",
    "# Function to calculate lift ratio between two brands\n",
    "def calculate_lift(brand1, brand2, total_posts):\n",
    "    if brand1 == brand2:\n",
    "        return 0  # Lift ratio between the same brand is 0\n",
    "    # Calculate lift using the formula: lift(brand1, brand2) = (P(brand1 and brand2) / (P(brand1) * P(brand2))) * N\n",
    "    p_brand1_and_brand2 = co_mentions[brand1][brand2]\n",
    "    p_brand1 = individual_mentions[brand1]\n",
    "    p_brand2 = individual_mentions[brand2]\n",
    "    if p_brand1 == 0 or p_brand2 == 0:\n",
    "        return 0  \n",
    "    else:\n",
    "        return (p_brand1_and_brand2 / (p_brand1 * p_brand2)) * total_posts\n",
    "\n",
    "# Iterate through the \"body\" column of the target DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    body_text = row['body']\n",
    "    \n",
    "    # Check for NaN values and skip them\n",
    "    if not isinstance(body_text, str) and np.isnan(body_text):\n",
    "        continue\n",
    "    \n",
    "    # Split the \"body\" text into words\n",
    "    words = body_text.split()\n",
    "    \n",
    "    # Convert words to lowercase for case-insensitive matching\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # Keep track of previously mentioned brands in the current post\n",
    "    mentioned_brands_in_post = set()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word in top_10_list:\n",
    "            # Check if the brand was already mentioned in the current post\n",
    "            if word not in mentioned_brands_in_post:\n",
    "                # Increment individual mention count for the brand\n",
    "                individual_mentions[word] += 1\n",
    "                # Update the set of mentioned brands in the current post\n",
    "                mentioned_brands_in_post.add(word)\n",
    "                \n",
    "                # Check for co-mentions of other brands in the same post\n",
    "                for j in range(i + 1, min(i + 6, len(words))):  # Change '6' to your desired separation limit\n",
    "                    if words[j] in top_10_list:\n",
    "                        # Increment co-mention count for the pair of brands (both directions)\n",
    "                        co_mentions[word][words[j]] += 1\n",
    "                        co_mentions[words[j]][word] += 1  # Symmetric update\n",
    "\n",
    "# Calculate total number of posts\n",
    "total_posts = len(df)\n",
    "\n",
    "lift_ratios = {}\n",
    "lift_already_calculated = set()  # To keep track of already calculated lift pairs\n",
    "\n",
    "for brand1 in top_10_list:\n",
    "    for brand2 in top_10_list:\n",
    "        if brand1 != brand2:\n",
    "            # Ensure we calculate lift only once for each pair (ignoring the order)\n",
    "            pair = tuple(sorted([brand1, brand2]))\n",
    "            if pair not in lift_already_calculated:\n",
    "                lift_ratio = calculate_lift(brand1, brand2, total_posts)\n",
    "                lift_ratios[pair] = lift_ratio\n",
    "                lift_already_calculated.add(pair)\n",
    "\n",
    "# Sort lift ratios in descending order\n",
    "sorted_lift_ratios = sorted(lift_ratios.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 unique lift ratios and associated brand pairs\n",
    "for (brand1, brand2), lift_ratio in sorted_lift_ratios[:10]:\n",
    "    print(f'Lift({brand1}, {brand2}) = {lift_ratio:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
